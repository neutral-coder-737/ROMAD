diff --git a/ultralytics/ultralytics/engine/results.py b/ultralytics/ultralytics/engine/results.py
index 256d2f1..30e7898 100644
--- a/ultralytics/ultralytics/engine/results.py
+++ b/ultralytics/ultralytics/engine/results.py
@@ -235,7 +235,7 @@ class Results(SimpleClass):
     """
 
     def __init__(
-        self, orig_img, path, names, boxes=None, masks=None, probs=None, keypoints=None, obb=None, speed=None
+        self, orig_img, path, names, boxes=None, masks=None, probs=None, keypoints=None, obb=None, speed=None, extra={}
     ) -> None:
         """
         Initialize the Results class for storing and manipulating inference results.
@@ -276,6 +276,7 @@ class Results(SimpleClass):
         self.path = path
         self.save_dir = None
         self._keys = "boxes", "masks", "probs", "keypoints", "obb"
+        self.extra = extra
 
     def __getitem__(self, idx):
         """
diff --git a/ultralytics/ultralytics/models/rtdetr/predict.py b/ultralytics/ultralytics/models/rtdetr/predict.py
index c6947b0..0cd47fe 100644
--- a/ultralytics/ultralytics/models/rtdetr/predict.py
+++ b/ultralytics/ultralytics/models/rtdetr/predict.py
@@ -46,6 +46,8 @@ class RTDETRPredictor(BasePredictor):
             (List[Results]): A list of Results objects containing the post-processed bounding boxes, confidence scores,
                 and class labels.
         """
+        dec_embs = preds[1][4]
+
         if not isinstance(preds, (list, tuple)):  # list for PyTorch inference but list[0] Tensor for export inference
             preds = [preds, None]
 
@@ -56,7 +58,7 @@ class RTDETRPredictor(BasePredictor):
             orig_imgs = ops.convert_torch2numpy_batch(orig_imgs)
 
         results = []
-        for bbox, score, orig_img, img_path in zip(bboxes, scores, orig_imgs, self.batch[0]):  # (300, 4)
+        for bbox, score, dec_emb, orig_img, img_path in zip(bboxes, scores, dec_embs, orig_imgs, self.batch[0]):  # (300, 4)
             bbox = ops.xywh2xyxy(bbox)
             max_score, cls = score.max(-1, keepdim=True)  # (300, 1)
             idx = max_score.squeeze(-1) > self.args.conf  # (300, )
@@ -66,7 +68,7 @@ class RTDETRPredictor(BasePredictor):
             oh, ow = orig_img.shape[:2]
             pred[..., [0, 2]] *= ow  # scale x coordinates to original width
             pred[..., [1, 3]] *= oh  # scale y coordinates to original height
-            results.append(Results(orig_img, path=img_path, names=self.model.names, boxes=pred))
+            results.append(Results(orig_img, path=img_path, names=self.model.names, boxes=pred, extra={"dec_embs": dec_emb[idx], "selected_indices":torch.where(idx)[0]}))
         return results
 
     def pre_transform(self, im):
diff --git a/ultralytics/ultralytics/nn/modules/head.py b/ultralytics/ultralytics/nn/modules/head.py
index 6cc208c..728eb8f 100644
--- a/ultralytics/ultralytics/nn/modules/head.py
+++ b/ultralytics/ultralytics/nn/modules/head.py
@@ -691,7 +691,7 @@ class RTDETRDecoder(nn.Module):
         embed, refer_bbox, enc_bboxes, enc_scores = self._get_decoder_input(feats, shapes, dn_embed, dn_bbox)
 
         # Decoder
-        dec_bboxes, dec_scores = self.decoder(
+        dec_bboxes, dec_scores, dec_embs = self.decoder(
             embed,
             refer_bbox,
             feats,
@@ -701,7 +701,7 @@ class RTDETRDecoder(nn.Module):
             self.query_pos_head,
             attn_mask=attn_mask,
         )
-        x = dec_bboxes, dec_scores, enc_bboxes, enc_scores, dn_meta
+        x = dec_bboxes, dec_scores, enc_bboxes, enc_scores, dec_embs, dn_meta
         if self.training:
             return x
         # (bs, 300, 4+nc)
diff --git a/ultralytics/ultralytics/nn/modules/transformer.py b/ultralytics/ultralytics/nn/modules/transformer.py
index 6d53441..9e04b0e 100644
--- a/ultralytics/ultralytics/nn/modules/transformer.py
+++ b/ultralytics/ultralytics/nn/modules/transformer.py
@@ -710,4 +710,4 @@ class DeformableTransformerDecoder(nn.Module):
             last_refined_bbox = refined_bbox
             refer_bbox = refined_bbox.detach() if self.training else refined_bbox
 
-        return torch.stack(dec_bboxes), torch.stack(dec_cls)
+        return torch.stack(dec_bboxes), torch.stack(dec_cls), output
diff --git a/ultralytics/ultralytics/nn/tasks.py b/ultralytics/ultralytics/nn/tasks.py
index aecd1b9..6f5a2f1 100644
--- a/ultralytics/ultralytics/nn/tasks.py
+++ b/ultralytics/ultralytics/nn/tasks.py
@@ -632,7 +632,7 @@ class RTDETRDetectionModel(DetectionModel):
         }
 
         preds = self.predict(img, batch=targets) if preds is None else preds
-        dec_bboxes, dec_scores, enc_bboxes, enc_scores, dn_meta = preds if self.training else preds[1]
+        dec_bboxes, dec_scores, enc_bboxes, enc_scores, _, dn_meta = preds if self.training else preds[1]
         if dn_meta is None:
             dn_bboxes, dn_scores = None, None
         else:
@@ -681,6 +681,9 @@ class RTDETRDetectionModel(DetectionModel):
                     return torch.unbind(torch.cat(embeddings, 1), dim=0)
         head = self.model[-1]
         x = head([y[j] for j in head.f], batch)  # head inference
+
+        _, dec_scores, _, _, dec_embs, _ = x[1]
+        dec_scores = dec_scores.squeeze(0).sigmoid() # (bsz, num_queries, num_classes)
         return x
 
 
